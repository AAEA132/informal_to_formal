{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from jiwer import wer, cer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory\n",
    "OUTPUT_DIR = './output_1/'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths for saving/loading\n",
    "DATASET_PATH = './exportStatements.xlsx'\n",
    "VOCAB_PATH = os.path.join(OUTPUT_DIR, 'word_vocab.pkl')\n",
    "PREPROCESSED_DATA_PATH = os.path.join(OUTPUT_DIR, 'preprocessed_data_word.pkl')\n",
    "BEST_MODEL_PATH = os.path.join(OUTPUT_DIR, 'best_transformer_model_word.pt')\n",
    "BEST_CER_MODEL_PATH = os.path.join(OUTPUT_DIR, 'best_transformer_model_cer.pt')\n",
    "LOSS_PLOT_PATH = os.path.join(OUTPUT_DIR, 'transformer_loss_plot_char.png')\n",
    "WER_PLOT_PATH = os.path.join(OUTPUT_DIR, 'wer_plot.png')\n",
    "CER_PLOT_PATH = os.path.join(OUTPUT_DIR, 'cer_plot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_excel(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in 'inFormalForm' and 'FormalForm'\n",
    "print(\"Missing values in 'inFormalForm':\", df['inFormalForm'].isnull().sum())\n",
    "print(\"Missing values in 'FormalForm':\", df['FormalForm'].isnull().sum())\n",
    "\n",
    "# Drop rows with missing values in 'inFormalForm' and 'FormalForm'\n",
    "initial_length = len(df)\n",
    "df = df.dropna(subset=['inFormalForm', 'FormalForm']).reset_index(drop=True)\n",
    "final_length = len(df)\n",
    "\n",
    "df['inFormalForm'] = df['inFormalForm'].astype(str)\n",
    "df['FormalForm'] = df['FormalForm'].astype(str)\n",
    "\n",
    "print(f\"Dropped {initial_length - final_length} rows due to missing values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training, validation, and test sets (80%, 10%, 10%)\n",
    "train_df, temp_df = train_test_split(df, test_size=0.2, random_state=SEED)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build word vocabulary from training data\n",
    "if not os.path.exists(VOCAB_PATH):\n",
    "    print('Building word vocabulary...')\n",
    "    from collections import Counter\n",
    "\n",
    "    # Simple tokenizer function\n",
    "    def tokenize(text):\n",
    "        # Define the regular expression for tokenization\n",
    "        # - \\w+: Matches sequences of word characters (letters, numbers, underscores)\n",
    "        # - [^\\s\\w]+: Matches sequences of characters that are not whitespace or word characters (e.g., punctuation)\n",
    "        token_pattern = r'\\w+|[^\\s\\w]+'\n",
    "\n",
    "        # Use re.findall to extract all matches of the token pattern from the text\n",
    "        tokens = re.findall(token_pattern, text)\n",
    "\n",
    "        return tokens\n",
    "\n",
    "    # Collect all words from the training data\n",
    "    all_words = []\n",
    "    for text in train_df['inFormalForm'].tolist() + train_df['FormalForm'].tolist():\n",
    "        tokens = tokenize(text)\n",
    "        all_words.extend(tokens)\n",
    "\n",
    "    # Build vocabulary\n",
    "    word_counts = Counter(all_words)\n",
    "    words = sorted(word_counts.keys())\n",
    "\n",
    "    # Add special tokens\n",
    "    special_tokens = ['<pad>', '<unk>', '<s>', '</s>']\n",
    "    word2idx = {word: idx + len(special_tokens) for idx, word in enumerate(words)}\n",
    "    for idx, token in enumerate(special_tokens):\n",
    "        word2idx[token] = idx\n",
    "    idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "\n",
    "    # Save vocabulary\n",
    "    with open(VOCAB_PATH, 'wb') as f:\n",
    "        pickle.dump({'word2idx': word2idx, 'idx2word': idx2word}, f)\n",
    "    print('Word vocabulary built and saved.')\n",
    "else:\n",
    "    print('Loading existing word vocabulary...')\n",
    "    with open(VOCAB_PATH, 'rb') as f:\n",
    "        vocab = pickle.load(f)\n",
    "        word2idx = vocab['word2idx']\n",
    "        idx2word = vocab['idx2word']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special token IDs\n",
    "PAD_IDX = word2idx['<pad>']\n",
    "UNK_IDX = word2idx['<unk>']\n",
    "BOS_IDX = word2idx['<s>']\n",
    "EOS_IDX = word2idx['</s>']\n",
    "\n",
    "PAD_IDX, UNK_IDX, BOS_IDX, EOS_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum sequence length (based on dataset)\n",
    "def get_max_len(df_list):\n",
    "    max_len = 0\n",
    "    for df in df_list:\n",
    "        lengths_src = df['inFormalForm'].apply(lambda x: len(tokenize(x)) + 2)  # +2 for BOS and EOS\n",
    "        lengths_trg = df['FormalForm'].apply(lambda x: len(tokenize(x)) + 2)\n",
    "        max_len = max(max_len, lengths_src.max(), lengths_trg.max())\n",
    "    return max_len\n",
    "\n",
    "MAX_LEN = get_max_len([train_df, val_df, test_df])\n",
    "\n",
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if preprocessed data exists\n",
    "if not os.path.exists(PREPROCESSED_DATA_PATH):\n",
    "    print('Preprocessing data...')\n",
    "    # Preprocess and tokenize all sentences\n",
    "    def preprocess_data(df, word2idx, max_len=MAX_LEN):\n",
    "        src_texts = df['inFormalForm'].tolist()\n",
    "        trg_texts = df['FormalForm'].tolist()\n",
    "        src_sequences = []\n",
    "        trg_sequences = []\n",
    "        for src, trg in zip(src_texts, trg_texts):\n",
    "            src_tokens = tokenize(src)\n",
    "            trg_tokens = tokenize(trg)\n",
    "            src_ids = [BOS_IDX] + [word2idx.get(w, UNK_IDX) for w in src_tokens] + [EOS_IDX]\n",
    "            trg_ids = [BOS_IDX] + [word2idx.get(w, UNK_IDX) for w in trg_tokens] + [EOS_IDX]\n",
    "            # Pad or truncate sequences\n",
    "            src_ids = src_ids[:max_len] + [PAD_IDX] * max(0, max_len - len(src_ids))\n",
    "            trg_ids = trg_ids[:max_len] + [PAD_IDX] * max(0, max_len - len(trg_ids))\n",
    "            src_sequences.append(src_ids)\n",
    "            trg_sequences.append(trg_ids)\n",
    "        return src_sequences, trg_sequences\n",
    "    \n",
    "    # Tokenize and preprocess data\n",
    "    train_src, train_trg = preprocess_data(train_df, word2idx)\n",
    "    val_src, val_trg = preprocess_data(val_df, word2idx)\n",
    "    test_src, test_trg = preprocess_data(test_df, word2idx)\n",
    "\n",
    "    # Save preprocessed data\n",
    "    with open(PREPROCESSED_DATA_PATH, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'train_src': train_src,\n",
    "            'train_trg': train_trg,\n",
    "            'val_src': val_src,\n",
    "            'val_trg': val_trg,\n",
    "            'test_src': test_src,\n",
    "            'test_trg': test_trg,\n",
    "            'MAX_LEN': MAX_LEN\n",
    "        }, f)\n",
    "    print('Preprocessed data saved.')\n",
    "else:\n",
    "    print('Loading preprocessed data...')\n",
    "    # Load preprocessed data\n",
    "    with open(PREPROCESSED_DATA_PATH, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        train_src = data['train_src']\n",
    "        train_trg = data['train_trg']\n",
    "        val_src = data['val_src']\n",
    "        val_trg = data['val_trg']\n",
    "        test_src = data['test_src']\n",
    "        test_trg = data['test_trg']\n",
    "        MAX_LEN = data['MAX_LEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare datasets\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, src_sequences, trg_sequences):\n",
    "        self.src_sequences = src_sequences\n",
    "        self.trg_sequences = trg_sequences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_ids = torch.tensor(self.src_sequences[idx], dtype=torch.long)\n",
    "        trg_ids = torch.tensor(self.trg_sequences[idx], dtype=torch.long)\n",
    "        return src_ids, trg_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collate function to create masks and pad sequences\n",
    "def collate_fn(batch, pad_idx):\n",
    "    src_batch, trg_batch = zip(*batch)\n",
    "    src_batch = torch.nn.utils.rnn.pad_sequence(src_batch, padding_value=pad_idx, batch_first=True)\n",
    "    trg_batch = torch.nn.utils.rnn.pad_sequence(trg_batch, padding_value=pad_idx, batch_first=True)\n",
    "    return src_batch, trg_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and dataloaders\n",
    "batch_size = 32  # Adjust as needed\n",
    "\n",
    "train_dataset = TranslationDataset(train_src, train_trg)\n",
    "val_dataset = TranslationDataset(val_src, val_trg)\n",
    "test_dataset = TranslationDataset(test_src, test_trg)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=lambda x: collate_fn(x, PAD_IDX))\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=lambda x: collate_fn(x, PAD_IDX))\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=lambda x: collate_fn(x, PAD_IDX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate subsequent masks for target\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = torch.triu(torch.ones((sz, sz), device=DEVICE) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create padding masks\n",
    "def create_mask(src, tgt, pad_idx):\n",
    "    src_seq_len = src.size(1)\n",
    "    tgt_seq_len = tgt.size(1)\n",
    "\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len), device=DEVICE).type(torch.bool)\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "\n",
    "    src_padding_mask = (src == pad_idx)\n",
    "    tgt_padding_mask = (tgt == pad_idx)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Model Definition (same as before)\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self, num_encoder_layers, num_decoder_layers, emb_size,\n",
    "                 nhead, src_vocab_size, tgt_vocab_size, dim_feedforward=512,\n",
    "                 dropout=0.1, max_len=MAX_LEN, pad_idx=PAD_IDX):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        self.src_vocab_size = src_vocab_size\n",
    "        self.tgt_vocab_size = tgt_vocab_size\n",
    "        self.emb_size = emb_size\n",
    "        self.pad_idx = pad_idx\n",
    "        self.max_len = max_len\n",
    "\n",
    "        # Token embedding layers\n",
    "        self.src_embedding = nn.Embedding(src_vocab_size, emb_size, padding_idx=pad_idx)\n",
    "        self.tgt_embedding = nn.Embedding(tgt_vocab_size, emb_size, padding_idx=pad_idx)\n",
    "\n",
    "        # Learned positional embeddings\n",
    "        self.src_pos_embedding = nn.Embedding(max_len, emb_size)\n",
    "        self.tgt_pos_embedding = nn.Embedding(max_len, emb_size)\n",
    "\n",
    "        # Transformer\n",
    "        self.transformer = nn.Transformer(d_model=emb_size, nhead=nhead,\n",
    "                                          num_encoder_layers=num_encoder_layers,\n",
    "                                          num_decoder_layers=num_decoder_layers,\n",
    "                                          dim_feedforward=dim_feedforward,\n",
    "                                          dropout=dropout)\n",
    "\n",
    "        # Output layer\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "\n",
    "    def forward(self, src, tgt, src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, memory_key_padding_mask):\n",
    "        # src and tgt shape: [batch_size, seq_len]\n",
    "        src_seq_len = src.size(1)\n",
    "        tgt_seq_len = tgt.size(1)\n",
    "        src_positions = torch.arange(0, src_seq_len, device=src.device).unsqueeze(0).expand(src.size(0), -1)\n",
    "        tgt_positions = torch.arange(0, tgt_seq_len, device=tgt.device).unsqueeze(0).expand(tgt.size(0), -1)\n",
    "\n",
    "        # Embed and encode source\n",
    "        src_emb = self.src_embedding(src) + self.src_pos_embedding(src_positions)\n",
    "        src_emb = src_emb * math.sqrt(self.emb_size)\n",
    "        # Embed and encode target\n",
    "        tgt_emb = self.tgt_embedding(tgt) + self.tgt_pos_embedding(tgt_positions)\n",
    "        tgt_emb = tgt_emb * math.sqrt(self.emb_size)\n",
    "\n",
    "        # Transformer\n",
    "        output = self.transformer(src_emb.transpose(0,1), tgt_emb.transpose(0,1),\n",
    "                                  src_mask, tgt_mask, None,\n",
    "                                  src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "        output = output.transpose(0,1)\n",
    "        logits = self.generator(output)\n",
    "        return logits\n",
    "\n",
    "    def encode(self, src, src_mask):\n",
    "        src_seq_len = src.size(1)\n",
    "        src_positions = torch.arange(0, src_seq_len, device=src.device).unsqueeze(0).expand(src.size(0), -1)\n",
    "        src_emb = self.src_embedding(src) + self.src_pos_embedding(src_positions)\n",
    "        src_emb = src_emb * math.sqrt(self.emb_size)\n",
    "        return self.transformer.encoder(src_emb.transpose(0,1), src_mask)\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask):\n",
    "        tgt_seq_len = tgt.size(1)\n",
    "        tgt_positions = torch.arange(0, tgt_seq_len, device=tgt.device).unsqueeze(0).expand(tgt.size(0), -1)\n",
    "        tgt_emb = self.tgt_embedding(tgt) + self.tgt_pos_embedding(tgt_positions)\n",
    "        tgt_emb = tgt_emb * math.sqrt(self.emb_size)\n",
    "        return self.transformer.decoder(tgt_emb.transpose(0,1), memory, tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model parameters\n",
    "VOCAB_SIZE = len(word2idx)\n",
    "SRC_VOCAB_SIZE = VOCAB_SIZE\n",
    "TGT_VOCAB_SIZE = VOCAB_SIZE\n",
    "\n",
    "# Hyperparameters (same as before)\n",
    "num_encoder_layers = 3\n",
    "num_decoder_layers = 3\n",
    "emb_size = 256\n",
    "nhead = 8\n",
    "dim_feedforward = 256\n",
    "dropout = 0.1  # Adjust dropout rate as needed\n",
    "\n",
    "\n",
    "model = Seq2SeqTransformer(num_encoder_layers, num_decoder_layers, emb_size,\n",
    "                           nhead, SRC_VOCAB_SIZE, TGT_VOCAB_SIZE,\n",
    "                           dim_feedforward, dropout, MAX_LEN, PAD_IDX).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-5)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "# # Initialize optimizer and loss function\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.0005)  # Adjusted learning rate for Transformer\n",
    "# criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_wer(model, dataloader, idx2word, max_batches=None):\n",
    "    model.eval()\n",
    "    cer_scores = []\n",
    "    wer_scores = []\n",
    "    batches_processed = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for src, trg in dataloader:\n",
    "            src = src.to(DEVICE)\n",
    "            trg = trg.to(DEVICE)\n",
    "\n",
    "            src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, trg[:, :-1], PAD_IDX)\n",
    "\n",
    "            output = model(src, trg[:, :-1], src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "            output = output.argmax(dim=-1)\n",
    "\n",
    "            trg_out = trg[:, 1:]  # Remove first token (<s>) for target\n",
    "            output = output.cpu().tolist()\n",
    "            trg_out = trg_out.cpu().tolist()\n",
    "\n",
    "            for pred_ids, trg_ids in zip(output, trg_out):\n",
    "                # Remove PAD and special tokens\n",
    "                pred_ids = [idx for idx in pred_ids if idx not in [PAD_IDX, EOS_IDX, UNK_IDX]]\n",
    "                trg_ids = [idx for idx in trg_ids if idx not in [PAD_IDX, EOS_IDX, UNK_IDX]]\n",
    "\n",
    "                pred_sentence = ' '.join([idx2word.get(idx, '') for idx in pred_ids])\n",
    "                trg_sentence = ' '.join([idx2word.get(idx, '') for idx in trg_ids])\n",
    "\n",
    "                cer_score = cer(trg_sentence, pred_sentence)\n",
    "                wer_score = wer(trg_sentence, pred_sentence)\n",
    "\n",
    "                cer_scores.append(cer_score)\n",
    "                wer_scores.append(wer_score)\n",
    "\n",
    "            batches_processed += 1\n",
    "            if max_batches and batches_processed >= max_batches:\n",
    "                break\n",
    "\n",
    "    avg_cer = np.mean(cer_scores)\n",
    "    avg_wer = np.mean(wer_scores)\n",
    "    return avg_cer, avg_wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop with WER calculation (same as before)\n",
    "N_EPOCHS = 100\n",
    "CLIP = 1  # Enable gradient clipping\n",
    "best_valid_loss = float('inf')\n",
    "best_valid_cer = float('inf')\n",
    "patience = 5\n",
    "counter = 0\n",
    "\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "train_wers = []\n",
    "valid_wers = []\n",
    "train_cers = []\n",
    "valid_cers = []\n",
    "\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Training\n",
    "    model.train()\n",
    "    epoch_train_loss = 0\n",
    "    for src, trg in tqdm(train_loader, desc=f'Training Epoch {epoch}/{N_EPOCHS}'):\n",
    "        src = src.to(DEVICE)\n",
    "        trg = trg.to(DEVICE)\n",
    "\n",
    "        # Create masks\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, trg[:, :-1], PAD_IDX)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg[:, :-1], src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        # output: [batch_size, tgt_len - 1, vocab_size]\n",
    "        # trg_out: [batch_size, tgt_len - 1]\n",
    "        trg_out = trg[:, 1:]\n",
    "\n",
    "        output = output.reshape(-1, TGT_VOCAB_SIZE)\n",
    "        trg_out = trg_out.reshape(-1)\n",
    "\n",
    "        loss = criterion(output, trg_out)\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient clipping\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_train_loss += loss.item()\n",
    "\n",
    "    epoch_train_loss /= len(train_loader)\n",
    "    train_losses.append(epoch_train_loss)\n",
    "    \n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    epoch_valid_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, trg in tqdm(val_loader, desc=f'Validation Epoch {epoch}/{N_EPOCHS}'):\n",
    "            src = src.to(DEVICE)\n",
    "            trg = trg.to(DEVICE)\n",
    "\n",
    "            src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, trg[:, :-1], PAD_IDX)\n",
    "\n",
    "            output = model(src, trg[:, :-1], src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "            trg_out = trg[:, 1:]\n",
    "\n",
    "            output = output.reshape(-1, TGT_VOCAB_SIZE)\n",
    "            trg_out = trg_out.reshape(-1)\n",
    "\n",
    "            loss = criterion(output, trg_out)\n",
    "            epoch_valid_loss += loss.item()\n",
    "\n",
    "    epoch_valid_loss /= len(val_loader)\n",
    "    valid_losses.append(epoch_valid_loss)\n",
    "\n",
    "    # Evaluate WER\n",
    "    valid_cer, valid_wer = evaluate_wer(model, val_loader, idx2word)\n",
    "    valid_wers.append(valid_wer)\n",
    "    valid_cers.append(valid_cer)\n",
    "    \n",
    "\n",
    "    train_subset_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=lambda x: collate_fn(x, PAD_IDX))\n",
    "    train_cer, train_wer = evaluate_wer(model, train_subset_loader, idx2word, max_batches=5)\n",
    "    train_wers.append(train_wer)\n",
    "    train_cers.append(train_cer)\n",
    "    \n",
    "    print(f'\\tTrain Loss: {epoch_train_loss:.3f}')\n",
    "    print(f'\\tValid Loss: {epoch_valid_loss:.3f}')\n",
    "    print(f'\\tTrain WER: {train_wer:.4f}')\n",
    "    print(f'\\tValid WER: {valid_wer:.4f}')\n",
    "    print(f'\\tTrain CER: {train_cer:.4f}')\n",
    "    print(f'\\tValid CER: {valid_cer:.4f}')\n",
    "    \n",
    "    # Early stopping check\n",
    "    if epoch_valid_loss < best_valid_loss:\n",
    "        best_valid_loss = epoch_valid_loss\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        print(f'Validation loss improved. Model saved to {BEST_MODEL_PATH}.')\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print('Early stopping triggered.')\n",
    "            break\n",
    "\n",
    "    if valid_cer < best_valid_cer:\n",
    "        best_valid_cer = valid_cer\n",
    "        torch.save(model.state_dict(), BEST_CER_MODEL_PATH)\n",
    "        print(f'Validation CER improved. Model saved to {BEST_CER_MODEL_PATH}.')\n",
    "    \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = divmod(int(end_time - start_time), 60)\n",
    "\n",
    "    print(f'Epoch: {epoch:02} | Time: {epoch_mins}m {epoch_secs}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss (same as before)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, len(valid_losses) + 1), valid_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.savefig(LOSS_PLOT_PATH)\n",
    "plt.show()\n",
    "print(f'Loss plot saved to {LOSS_PLOT_PATH}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot WER over epochs\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, len(train_wers) + 1), train_wers, label='Train WER')\n",
    "plt.plot(range(1, len(valid_wers) + 1), valid_wers, label='Validation WER')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('WER')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation WER Over Epochs')\n",
    "plt.savefig(WER_PLOT_PATH)\n",
    "plt.show()\n",
    "print(f'WER plot saved to {WER_PLOT_PATH}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot CER over epochs\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, len(train_cers) + 1), train_cers, label='Train CER')\n",
    "plt.plot(range(1, len(valid_cers) + 1), valid_cers, label='Validation CER')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('CER')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation CER Over Epochs')\n",
    "plt.savefig(CER_PLOT_PATH)\n",
    "plt.show()\n",
    "print(f'CER plot saved to {CER_PLOT_PATH}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for inference\n",
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        tgt_mask = generate_square_subsequent_mask(ys.size(1)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0,1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        next_word = torch.argmax(prob, dim=1).item()\n",
    "        ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, model, word2idx, idx2word, device, max_len=MAX_LEN, decoding_strategy='greedy'):\n",
    "    model.eval()\n",
    "    tokens = tokenize(sentence)\n",
    "    tokens = [BOS_IDX] + [word2idx.get(w, UNK_IDX) for w in tokens] + [EOS_IDX]\n",
    "    tokens = tokens[:max_len]\n",
    "    src = torch.tensor(tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
    "    src_mask = (torch.zeros(src.shape[1], src.shape[1])).type(torch.bool).to(device)\n",
    "    if decoding_strategy == 'greedy':\n",
    "        tgt_tokens = greedy_decode(model, src, src_mask, max_len, BOS_IDX).flatten()\n",
    "    elif decoding_strategy == 'beam':\n",
    "        # Implement beam search decoding as needed\n",
    "        raise NotImplementedError(\"Beam search decoding is not implemented yet.\")\n",
    "    else:\n",
    "        raise ValueError(\"Invalid decoding strategy\")\n",
    "    tgt_tokens = tgt_tokens.cpu().numpy()\n",
    "    # Remove BOS token\n",
    "    tgt_tokens = tgt_tokens[1:]\n",
    "    # Stop at EOS token\n",
    "    if EOS_IDX in tgt_tokens:\n",
    "        eos_index = np.where(tgt_tokens == EOS_IDX)[0][0]\n",
    "        tgt_tokens = tgt_tokens[:eos_index]\n",
    "    translation = ' '.join([idx2word.get(idx, '') for idx in tgt_tokens if idx not in [PAD_IDX, BOS_IDX, EOS_IDX, UNK_IDX]])\n",
    "    return translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate CER and WER\n",
    "def calculate_metrics(references, hypotheses):\n",
    "    cer_scores = []\n",
    "    wer_scores = []\n",
    "    for ref, hyp in zip(references, hypotheses):\n",
    "        cer_score = cer(ref, hyp)\n",
    "        wer_score = wer(ref, hyp)\n",
    "        cer_scores.append(cer_score)\n",
    "        wer_scores.append(wer_score)\n",
    "    avg_cer = np.mean(cer_scores)\n",
    "    avg_wer = np.mean(wer_scores)\n",
    "    return avg_cer, avg_wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate and save results\n",
    "def evaluate_and_save(model, df, src_sequences, trg_sequences, word2idx, idx2word, file_name):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    cer_scores = []\n",
    "    wer_scores = []\n",
    "\n",
    "    for src_ids, trg_ids in tqdm(zip(src_sequences, trg_sequences), total=len(src_sequences), desc=f'Evaluating {file_name}'):\n",
    "        src_sentence = ' '.join([idx2word.get(idx, '') for idx in src_ids if idx not in [BOS_IDX, EOS_IDX, PAD_IDX]])\n",
    "        trg_sentence = ' '.join([idx2word.get(idx, '') for idx in trg_ids if idx not in [BOS_IDX, EOS_IDX, PAD_IDX]])\n",
    "\n",
    "        pred_sentence = translate_sentence(src_sentence, model, word2idx, idx2word, DEVICE)\n",
    "        predictions.append(pred_sentence)\n",
    "        cer_score = cer(trg_sentence, pred_sentence)\n",
    "        wer_score = wer(trg_sentence, pred_sentence)\n",
    "        cer_scores.append(cer_score)\n",
    "        wer_scores.append(wer_score)\n",
    "\n",
    "    results_df = pd.DataFrame({\n",
    "        'Source': df['inFormalForm'],\n",
    "        'Target': df['FormalForm'],\n",
    "        'Prediction': predictions,\n",
    "        'CER': cer_scores,\n",
    "        'WER': wer_scores\n",
    "    })\n",
    "    \n",
    "    results_df = results_df.sort_values(by=['CER', 'WER'], ascending=[True, True])\n",
    "\n",
    "    results_path = os.path.join(OUTPUT_DIR, file_name)\n",
    "    results_df.to_csv(results_path, index=False)\n",
    "    avg_cer = np.mean(cer_scores)\n",
    "    avg_wer = np.mean(wer_scores)\n",
    "    print(f'Results saved to {results_path}')\n",
    "    print(f'Average CER: {avg_cer:.4f}')\n",
    "    print(f'Average WER: {avg_wer:.4f}')\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "model.load_state_dict(torch.load(BEST_MODEL_PATH))\n",
    "print('Best model loaded.')\n",
    "\n",
    "# Evaluate on training data\n",
    "print('Evaluating on training data...')\n",
    "train_results = evaluate_and_save(model, train_df, train_src, train_trg, word2idx, idx2word, 'train_results_word_transformer.csv')\n",
    "\n",
    "# Evaluate on validation data\n",
    "print('Evaluating on validation data...')\n",
    "val_results = evaluate_and_save(model, val_df, val_src, val_trg, word2idx, idx2word, 'val_results_word_transformer.csv')\n",
    "\n",
    "# Evaluate on test data\n",
    "print('Evaluating on test data...')\n",
    "test_results = evaluate_and_save(model, test_df, test_src, test_trg, word2idx, idx2word, 'test_results_word_transformer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best CER model\n",
    "model.load_state_dict(torch.load(BEST_CER_MODEL_PATH))\n",
    "print('Best CER model loaded.')\n",
    "\n",
    "# Evaluate on training data\n",
    "print('Evaluating on training data using best CER model...')\n",
    "train_results = evaluate_and_save(model, train_df, train_src, train_trg, word2idx, idx2word, 'train_results_best_cer.csv')\n",
    "\n",
    "# Evaluate on validation data\n",
    "print('Evaluating on validation data using best CER model...')\n",
    "val_results = evaluate_and_save(model, val_df, val_src, val_trg, word2idx, idx2word, 'val_results_best_cer.csv')\n",
    "\n",
    "# Evaluate on test data using the best CER model\n",
    "print('Evaluating on test data using best CER model...')\n",
    "test_results = evaluate_and_save(model, test_df, test_src, test_trg, word2idx, idx2word, 'test_results_best_cer.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quera",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
